{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a classifiction algorithm that is using Bayes Theorem in order to provide prediction based on conditional probability of an event A given another event B occured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B) = \\frac{P(B|A) P(A)}{P(B)}$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ P(A|B) $ - conditional probability of A given B\n",
    "- $ P(B|A) $ - conditional probability of B given A\n",
    "- $ P(A) $ - probability of A\n",
    "- $ P(B) $ - probability of B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Example #1 - Coin Flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem\n",
    "Given two coins what's the probability of second coin being heads given first was tails.\n",
    "\n",
    "#### Let's write down probabilities\n",
    "\n",
    "Each coin has two posible states: head and tails. Therefore let's state:\n",
    "\n",
    "- $P(A)$ - probability of first coin being head\n",
    "- $P(B)$ - probability of second coin being head\n",
    "\n",
    "equals to:\n",
    "\n",
    "$P(A) = \\frac{1}{2}$ (1 - state which is head, divided by 2 - number of states)\n",
    "\n",
    "$P(B) = \\frac{1}{2}$ (1 - state which is head, divided by 2 - number of states)\n",
    "\n",
    "At the same time we can state that:\n",
    "\n",
    "- $P(A)'$ - probability of first coin being tails\n",
    "- $P(B)'$ - probability of second coin being tails\n",
    "\n",
    "equals to:\n",
    "\n",
    "$P(A') == P(A)$\n",
    "\n",
    "$P(B') == P(B)$\n",
    "\n",
    "Logic in this case says that both coins are not depended on each other so it shouldn't matter what will be the result of the first coin flip, probability of second coin being tails is always the same. So using already stated nomenclature it is possible to say:\n",
    "\n",
    "- $P(A'|B)$ - probability of first coin being tails given that second coin being head\n",
    "- $P(B|A')$ - probability of second coin being head given that first coin being tails\n",
    "\n",
    "$P(A'|B) = \\frac{1}{2}$\n",
    "\n",
    "$P(B|A') = \\frac{1}{2}$\n",
    "\n",
    "Now let's see if the Bayes Theorem will give the same result:\n",
    "\n",
    "$P(B|A') = \\frac{P(A'|B) P(B)}{P(A')} = \\frac{\\frac{1}{2} \\frac{1}{2}}{\\frac{1}{2}} = \\frac{1}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Example #2 - Dices\n",
    "\n",
    "#### Problem\n",
    "Given two dices, what's probability of getting sum of eyes equal to 9 given that first dice throw resulted in even number.\n",
    "\n",
    "#### Let's write down probabilities\n",
    "\n",
    "Each dice has possible six states: 1, 2, 3, 4, 5, 6. Let's write down all possibilities:\n",
    "\n",
    "| Dice 1 | Dice 2 | Sum | Meets Requirement |\n",
    "|------|------|------|------|\n",
    "|1|1|2|No|\n",
    "|2|1|3|No|\n",
    "|3|1|4|No|\n",
    "|4|1|5|No|\n",
    "|5|1|6|No|\n",
    "|6|1|7|No|\n",
    "|1|2|3|No|\n",
    "|2|2|4|No|\n",
    "|3|2|5|No|\n",
    "|4|2|6|No|\n",
    "|5|2|7|No|\n",
    "|6|2|8|No|\n",
    "|1|3|4|No|\n",
    "|2|3|5|No|\n",
    "|3|3|6|No|\n",
    "|4|3|7|No|\n",
    "|5|3|8|No|\n",
    "|6|3|9|Yes|\n",
    "|1|4|5|No|\n",
    "|2|4|6|No|\n",
    "|3|4|7|No|\n",
    "|4|4|8|No|\n",
    "|5|4|9|No|\n",
    "|6|4|10|No|\n",
    "|1|5|6|No|\n",
    "|2|5|7|No|\n",
    "|3|5|8|No|\n",
    "|4|5|9|Yes|\n",
    "|5|5|10|No|\n",
    "|6|5|11|No|\n",
    "|1|6|7|No|\n",
    "|2|6|8|No|\n",
    "|3|6|9|No|\n",
    "|4|6|10|No|\n",
    "|5|6|11|No|\n",
    "|6|6|12|No|\n",
    "\n",
    "Consequently it is possible to state:\n",
    "  \n",
    "- $P(A)$ - probability of first dice result being even\n",
    "- $P(B)$ - probability of sum of dices results being 9\n",
    "- $P(A|B)$ - probability of first dice throw resulted in even number, given that sum of dices results is 9\n",
    "- $P(B|A)$ - probability of sum of dices result being 9 given that first dice throw resulted in even number\n",
    "\n",
    "equals to:\n",
    "\n",
    "$P(A) = \\frac{3}{6} = \\frac{1}{2}$ (out of 6 options, possible are: 2, 4, 6)\n",
    "\n",
    "$P(B) = \\frac{4}{36} = \\frac{1}{9}$ (out of 36 options, possible are: (6,3), (5,4), (4,5), (3,6))\n",
    "\n",
    "$P(A|B) = \\frac{2}{36} = \\frac{1}{18}$ (out of 36 options, possible are: (6,3), (4,5))\n",
    "\n",
    "and finally:\n",
    "\n",
    "\n",
    "$P(B|A) = \\frac{P(A|B) P(B)}{P(A)} = \\frac{\\frac{1}{18}\\frac{1}{9}}{\\frac{1}{2}} = 0.012345679012345678$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Example #3 - Car Accident\n",
    "\n",
    "What's the probability of car having an accident given that driver is driving in summer, there is no rain, it's a night and it's an urban area?\n",
    "\n",
    "#### Mock data:\n",
    "\n",
    "| Season | Weather | Daytime | Area | Did Accident Occur? |\n",
    "|------|------|------|------|------|\n",
    "| Summer | No-Raining | Night | Urban | No |\n",
    "| Summer | No-Raining | Day | Urban | No |\n",
    "| Summer | Raining | Night | Rural | No |\n",
    "| Summer | Raining | Night | Urban | Yes |\n",
    "| Summer | Raining | Day | Urban | No |\n",
    "| Summer | Raining | Night | Rural | No |\n",
    "| Winter | Raining | Night | Urban | Yes |\n",
    "| Winter | Raining | Night | Urban | Yes |\n",
    "| Winter | Raining | Night | Rural | Yes |\n",
    "| Winter | No-Raining | Night | Rural | No |\n",
    "| Winter | No-Raining | Night | Urban | No |\n",
    "| Winter | No-Raining | Day | Urban | Yes |\n",
    "| Spring | No-Raining | Night | Rural | Yes |\n",
    "| Spring | No-Raining | Day | Rural | Yes |\n",
    "| Spring | Raining | Night | Urban | No |\n",
    "| Spring | Raining | Day | No | No |\n",
    "| Spring | No-Raining | Night | Urban | No |\n",
    "| Autumn | Raining | Night | Urban | Yes |\n",
    "| Autumn | Raining | Day | Rural | Yes |\n",
    "| Autumn | No-Raining | Night | Urban | No |\n",
    "| Autumn | No-Raining | Day | Rural | No |\n",
    "| Autumn | No-Raining | Day | Urban | No |\n",
    "| Autumn | Raining | Day | Yes | No |\n",
    "| Autumn | Raining | Night | Yes | No |\n",
    "| Autumn | No-Raining | Night | No | No |\n",
    "\n",
    "To handle data like this it is possible to calculate frequencies for each case:\n",
    "\n",
    "#### 0. Accident probability\n",
    "$P(Accident) = \\frac{9}{25} = 0.36$\n",
    "\n",
    "$P(No-Accident) = \\frac{16}{25} = 0.64$\n",
    "\n",
    "#### 1. Season probability\n",
    "\n",
    "Frequency table:\n",
    "\n",
    "| Season | Accident | No Accident | |\n",
    "|------|------|------|------|\n",
    "| Spring | 2/9 | 3/16 | 5/25 |\n",
    "| Summer | 1/9 | 5/16 | 6/25 |\n",
    "| Autumn | 2/9 | 6/16 | 8/25 |\n",
    "| Winter | 4/9 | 2/16 | 6/25 |\n",
    "| |9/25|16/25| |\n",
    "\n",
    "Probabilities based on table:\n",
    " \n",
    "$P(Spring) = \\frac{5}{25} = 0.20$\n",
    "\n",
    "$P(Summer) = \\frac{6}{25} = 0.24$\n",
    "\n",
    "$P(Autumn) = \\frac{8}{25} = 0.32$\n",
    "\n",
    "$P(Winter) = \\frac{6}{25} = 0.24$\n",
    "\n",
    "$P(Spring | Accident) = \\frac{2}{9} = 0.22$\n",
    "\n",
    "$P(Summer | Accident) = \\frac{1}{9} = 0.11$\n",
    "\n",
    "$P(Autumn | Accident) = \\frac{2}{9} = 0.22$\n",
    "\n",
    "$P(Winter | Accident) = \\frac{4}{9} = 0.44$\n",
    "\n",
    "#### 2. Weather probability\n",
    "\n",
    "Frequency table:\n",
    "\n",
    "| | Accident | No Accident | |\n",
    "|------|------|------|------|\n",
    "| Raining | 6/9 | 7/16 | 13/25 |\n",
    "| No-Raining | 3/9 | 9/16 | 12/25 |\n",
    "| | 9/25 | 16/25 | |\n",
    "\n",
    "Probabilities based on table:\n",
    "\n",
    "$P(Raining) = \\frac{13}{25} = 0.52$\n",
    "\n",
    "$P(No-Raining) = \\frac{12}{25} = 0.48$\n",
    "\n",
    "$P(Raining|Accident) = \\frac{6}{9} = 0.667$\n",
    "\n",
    "$P(No-Raining|Accident) = \\frac{12}{25} = 0.333$\n",
    "\n",
    "\n",
    "#### 3. Daytime probability\n",
    "\n",
    "Frequency table:\n",
    "\n",
    "| | Accident | No Accident | |\n",
    "|------|------|------|------|\n",
    "| Day | 3/9 | 6/16 | 9/25 |\n",
    "| Night | 6/9 | 10/16 | 16/25 |\n",
    "| | 9/25 | 16/25 | |\n",
    "\n",
    "Probabilities based on table:\n",
    "\n",
    "$P(Day) = \\frac{9}{25} = 0.36$\n",
    "\n",
    "$P(Night) = \\frac{16}{25} = 0.64$\n",
    "\n",
    "$P(Day|Accident) = \\frac{3}{9} = 0.333$\n",
    "\n",
    "$P(Night|Accident) = \\frac{6}{9} = 0.667$\n",
    "\n",
    "#### 4. Area probability\n",
    "\n",
    "Frequency table:\n",
    "\n",
    "| | Accident | No Accident | |\n",
    "|------|------|------|------|\n",
    "| Urban Area | 5/9 | 8/16 | 13/25 |\n",
    "| Rural Area | 4/9 | 8/16 | 12/25 |\n",
    "| | 9/25 | 16/25 | |\n",
    "\n",
    "Probabilities based on table:\n",
    "\n",
    "$P(Urban) = \\frac{13}{25} = 0.52$\n",
    "\n",
    "$P(Rural) = \\frac{12}{25} = 0.48$\n",
    "\n",
    "$P(Urban|Accident) = \\frac{5}{9} = 0.556$\n",
    "\n",
    "$P(Rural|Accident) = \\frac{4}{9} = 0.444$\n",
    "\n",
    "#### Assemble:\n",
    "\n",
    "Calculating probablity of car accident occuring in summer, when there is no rain and during night, in urban area.\n",
    "\n",
    "Where B equals to:\n",
    "- Season: Summer\n",
    "- Weather: No-Raining\n",
    "- Daytime: Night\n",
    "- Area: Urban\n",
    "\n",
    "Where A equals to:\n",
    "- Accident\n",
    "\n",
    "Using Naive Bayes:\n",
    "\n",
    "$P(A|B) = P(Accident | Season = Summer, Weather = No-Raining, Daytime = Night, Area = Urban)$\n",
    "\n",
    "$P(A|B) = \\frac{P(Summer|Accident)P(No-Raining|Accident)P(Night|Accident)P(Urban|Accident)P(Accident)}{P(Summer)P(No-Raining)P(Night)P(Urban)}$\n",
    "\n",
    "$P(A|B) = \\frac{\\frac{1}{9}\\frac{6}{9}\\frac{6}{9}\\frac{5}{9}\\frac{9}{25}}{\\frac{6}{25}\\frac{12}{25}\\frac{16}{25}\\frac{13}{25}} = \\frac{0.111\\cdot0.667\\cdot0.667\\cdot0.556\\cdot0.36}{0.24\\cdot0.48\\cdot0.64\\cdot0.52} = \\frac{0.0099}{0.038} = 0.26$\n",
    "\n",
    "*Luckily the data was made up :)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Example 4 - Iris\n",
    "\n",
    "To which type of Iris does the following sample belongs to?\n",
    "\n",
    "|Sepal Length| Sepal Width | Petal Length | Petal Width | Iris Type |\n",
    "|------|------|------|------|------|\n",
    "|6.3|3.4|5.6|2.4|?|\n",
    "\n",
    "\n",
    "Mock data:\n",
    "\n",
    "|Sepal Length| Sepal Width | Petal Length | Petal Width | Iris Type |\n",
    "|------|------|------|------|------|\n",
    "|5.1|3.8|1.6|0.2|Setosa|\n",
    "|4.6|3.2|1.4|0.2|Setosa|\n",
    "|5.3|3.7|1.5|0.2|Setosa|\n",
    "|5.0|3.3|1.4|0.2|Setosa|\n",
    "|7.0|3.2|4.7|1.4|Versicolor|\n",
    "|6.9|3.1|4.9|1.5|Versicolor|\n",
    "|5.0|2.0|3.5|1.0|Versicolor|\n",
    "|5.9|3.0|4.2|1.5|Versicolor|\n",
    "|6.3|3.3|6.0|2.5|Virginica|\n",
    "|4.9|2.5|4.5|1.7|Virginica|\n",
    "|7.3|2.9|6.3|1.8|Virginica|\n",
    "|6.7|2.5|5.8|1.8|Virginica|\n",
    "\n",
    "In this case, there are numerical values so it is impossible to use frequency count. To handle this problem Gaussian Naive Bayes will be used. For each class, there will be created a representation of this class which is **mean** and **standard deviation** of each feature describing this class. Then **Gaussian Probability Density Function** can be used do calculate what's the probabilty of query sample belonging to specific class:\n",
    "\n",
    "#### 1. Mean formula\n",
    "$$\\mu = \\frac{1}{m} \\sum_{i=1}^{m}x_i$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ \\mu $ - mean\n",
    "- $ m $ - amount of samples\n",
    "- $ i $ - sample index\n",
    "- $ x $ - sample value\n",
    "\n",
    "#### 2. Standard Deviation Formula\n",
    "$$\\sigma = \\sqrt{\\frac{1}{m - 1}\\sum_{i=1}^{m}(x_i - \\mu)^2} $$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ \\sigma $ - standard deviation\n",
    "- $ \\mu $ - mean\n",
    "- $ m $ - amount of samples\n",
    "- $ i $ - sample index\n",
    "- $ x $ - sample value\n",
    "\n",
    "#### 3. Gaussian Pobability Density Function\n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ \\sigma $ - standard deviation\n",
    "- $ \\mu $ - mean\n",
    "- $ e $ - Euler constant\n",
    "- $ x $ - sample value\n",
    "\n",
    "---\n",
    "\n",
    "### Problem Statement\n",
    "Let's solve the problem with Gaussian Naive Bayes, where:\n",
    "\n",
    "Where B equals to:\n",
    "- Sepal Length: 6.3\n",
    "- Sepal Width: 3.4\n",
    "- Petal Length: 5.6\n",
    "- Petal Width: 2.4\n",
    "\n",
    "Goal is to find largest posterior $P(A/B)$ where A is a **Class** and can equal to: \n",
    "- Setosa\n",
    "- Veriscolor\n",
    "- Virginica\n",
    "\n",
    "And the equation to calculate posterior of class is as follows:\n",
    "\n",
    "$P(Class | Sepal Length=6.3, Sepal Width=3.4, Petal Length=5.6, Petal Width=2.4) =$ \n",
    "$P(Sepal Length=6.3 | Class)P(Sepal Width=3.4 | Class)P(Petal Length=5.6 | Class)P(Petal Width=2.4 | Class)P(Class)$\n",
    "\n",
    "but comparing to Bayes theorem following formula is lacking scaling factor $P(B)$:\n",
    "\n",
    "$P(A|B) = \\frac{P(B|A) P(A)}{P(B)}$\n",
    "\n",
    "because in case of Gaussian Naive Bayes $P(B)$ **doesn't affect the result** so it can be ommitted. So the following formula is used:\n",
    "\n",
    "$P(A|B) \\approx P(B|A)P(A)$\n",
    "\n",
    "### Required Probabilities\n",
    "\n",
    "- In order to find posterior $P(Setosa | Sepal Length=6.3, Sepal Width=3.4, Petal Length=5.6, Petal Width=2.4)$:\n",
    "\n",
    "$P(Setosa) = \\frac{4}{12} = 0.33$ (because there are 4 cases of Setosa out of 12 cases in table)\n",
    "\n",
    "$ \\mu_{setosa-sl} = 5.0 $\n",
    "\n",
    "$ \\mu_{setosa-sw} = 3.5 $\n",
    "\n",
    "$ \\mu_{setosa-pl} = 1.475 $\n",
    "\n",
    "$ \\mu_{setosa-pw} = 0.2 $\n",
    "\n",
    "$ \\sigma_{setosa-sl} = 0.255 $\n",
    "\n",
    "$ \\sigma_{setosa-sw} = 0.255 $\n",
    "\n",
    "$ \\sigma_{setosa-pl} = 0.083 $\n",
    "\n",
    "$ \\sigma_{setosa-pw} = 0.0 $\n",
    "\n",
    "$P(Sepal Length=6.3 | Setosa) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.255}e^{-\\frac{(6.3 - 5.0)^2}{2\\cdot0.255^2}} = 0.0000035373$\n",
    "\n",
    "$P(Sepal Width=3.4 | Setosa) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.255}e^{-\\frac{(3.4 - 3.5)^2}{2\\cdot0.255^2}} = 1.4489243033$\n",
    "\n",
    "$P(Petal Length=5.6 | Setosa) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.083}e^{-\\frac{(5.6 - 1.475)^2}{2\\cdot0.083^2}} = 0.0$\n",
    "\n",
    "$P(Petal Width=2.4 | Setosa) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.0}e^{-\\frac{(2.4 - 0.2)^2}{2\\cdot0.0^2}} = 0.0$\n",
    "\n",
    "- In order to find posterior $P(Veriscolor | Sepal Length=6.3, Sepal Width=3.4, Petal Length=5.6, Petal Width=2.4)$:\n",
    "\n",
    "$P(Veriscolor) = \\frac{4}{12} = 0.33$ (because there are 4 cases of Veriscolor out of 12 cases in table)\n",
    "\n",
    "$ \\mu_{veriscolor-sl} = 6.2 $\n",
    "\n",
    "$ \\mu_{veriscolor-sw} = 2.825 $\n",
    "\n",
    "$ \\mu_{veriscolor-pl} = 4.325 $\n",
    "\n",
    "$ \\mu_{veriscolor-pw} = 1.35 $\n",
    "\n",
    "$ \\sigma_{veriscolor-sl} = 0.815 $\n",
    "\n",
    "$ \\sigma_{veriscolor-sw} = 0.482 $\n",
    "\n",
    "$ \\sigma_{veriscolor-pl} = 0.54 $\n",
    "\n",
    "$ \\sigma_{veriscolor-pw} = 0.206 $\n",
    "\n",
    "$P(Sepal Length=6.3 | Veriscolor) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.815}e^{-\\frac{(6.3 - 6.2)^2}{2\\cdot0.815^2}} = 0.4855496676$\n",
    "\n",
    "$P(Sepal Width=3.4 | Veriscolor) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.482}e^{-\\frac{(3.4 - 2.825)^2}{2\\cdot0.482^2}} = 0.4061237321$\n",
    "\n",
    "$P(Petal Length=5.6 | Veriscolor) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.54}e^{-\\frac{(5.6 - 4.325)^2}{2\\cdot0.54^2}} = 0.0455923085$\n",
    "\n",
    "$P(Petal Width=2.4 | Veriscolor) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.206}e^{-\\frac{(2.4 - 1.35)^2}{2\\cdot0.206^2}} = 0.0000045053$\n",
    "\n",
    "- In order to find posterior $P(Virginica | Sepal Length=6.3, Sepal Width=3.4, Petal Length=5.6, Petal Width=2.4)$:\n",
    "\n",
    "$P(Virginica) = \\frac{4}{12} = 0.33$ (because there are 4 cases of Virginica out of 12 cases in table)\n",
    "\n",
    "$ \\mu_{virginica-sl} = 6.3 $\n",
    "\n",
    "$ \\mu_{virginica-sw} = 2.8 $\n",
    "\n",
    "$ \\mu_{virginica-pl} = 5.65 $\n",
    "\n",
    "$ \\mu_{virginica-pw} = 1.95 $\n",
    "\n",
    "$ \\sigma_{virginica-sl} = 0.883 $\n",
    "\n",
    "$ \\sigma_{virginica-sw} = 0.332 $\n",
    "\n",
    "$ \\sigma_{virginica-pl} = 0.687 $\n",
    "\n",
    "$ \\sigma_{virginica-pw} = 0.320 $\n",
    "\n",
    "$P(Sepal Length=6.3 | Virginica) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.883}e^{-\\frac{(6.3 - 6.3)^2}{2\\cdot0.883^2}} = 0.4517129780$\n",
    "\n",
    "$P(Sepal Width=3.4 | Virginica) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.332}e^{-\\frac{(3.4 - 2.8)^2}{2\\cdot0.332^2}} = 0.2341815809$\n",
    "\n",
    "$P(Petal Length=5.6 | Virginica) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.687}e^{-\\frac{(5.6 - 5.65)^2}{2\\cdot0.687^2}} = 0.5788419280$\n",
    "\n",
    "$P(Petal Width=2.4 | Virginica) = \\frac{1}{\\sqrt{2\\pi}\\cdot0.32}e^{-\\frac{(2.4 - 1.95)^2}{2\\cdot0.32^2}} = 0.4640357888$\n",
    "\n",
    "#### Result\n",
    "\n",
    "Posterios for each class looks like follows:\n",
    "\n",
    "$P(Setosa | Sepal Length=6.3, Sepal Width=3.4, Petal Length=5.6, Petal Width=2.4) = 0.0$\n",
    "\n",
    "$P(Veriscolor | Sepal Length=6.3, Sepal Width=3.4, Petal Length=5.6, Petal Width=2.4) = 0.0000000135$\n",
    "\n",
    "$P(Virginica | Sepal Length=6.3, Sepal Width=3.4, Petal Length=5.6, Petal Width=2.4) = 0.0094712109$\n",
    "\n",
    "Consequently the answer is: \n",
    "\n",
    "|Sepal Length| Sepal Width | Petal Length | Petal Width | Iris Type |\n",
    "|------|------|------|------|------|\n",
    "|6.3|3.4|5.6|2.4|Virginica|\n",
    "\n",
    "as it's posterior for given data is the highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes - Raw Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T01:58:30.253105Z",
     "start_time": "2020-02-23T01:58:29.881911Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T01:58:30.258493Z",
     "start_time": "2020-02-23T01:58:30.254823Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Function loads dictionary containing iris dataset from scikit-learn\n",
    "    library and splits samples in stratified way, in 0.8/0.2 ratio, into \n",
    "    train and test datasets.\n",
    "    \"\"\"\n",
    "    iris = load_iris()\n",
    "    samples, targets = iris[\"data\"], iris[\"target\"]\n",
    "    return train_test_split(\n",
    "        samples, targets, \n",
    "        test_size=0.2, \n",
    "        stratify=targets,\n",
    "        shuffle=True, \n",
    "        random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T01:58:30.271269Z",
     "start_time": "2020-02-23T01:58:30.260549Z"
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    \"\"\"Implementation of Gaussian Naive Bayes algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Inits variables for storing class representations.\"\"\"\n",
    "        self.classes = None\n",
    "        self.class_priors = None\n",
    "        self.class_feature_mean = None\n",
    "        self.class_feature_std = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def _gaussian_probabiity_density_function(value, mean, std):\n",
    "        \"\"\"Implementation of Gaussian Probability Density Function. Used to tell what's the \n",
    "        probablity of \"value\" belonging to Gaussian Distribution described with \"mean\" and \"std\"\n",
    "        values. Link to equation: https://en.wikipedia.org/wiki/Gaussian_function\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        value: float\n",
    "            Value for which probability of belonging to distribution will be returned.\n",
    "        mean: float\n",
    "            Mean of modeled Gaussian Distribution.\n",
    "        std: float\n",
    "            Standard Deviation of modeled Gaussian Distribution.\n",
    "            \n",
    "        Returns:\n",
    "        -----------\n",
    "        probability: float\n",
    "            Probability of value belonging to distribution.\n",
    "        \"\"\"\n",
    "        eps = 1e-4\n",
    "        exponent = np.exp(-((value - mean)**2) / (2.0 * std**2 + eps))\n",
    "        coefficient = 1.0 / (np.sqrt(2.0 * np.pi) * std + eps)\n",
    "        probability = coefficient * exponent\n",
    "        return probability\n",
    "        \n",
    "    def _set_prior_for_classes(self, y):\n",
    "        \"\"\"Sets prior (probability of occurence) for each class.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        y: numpy.array\n",
    "            Vector containing class id for each training sample in vector \"x\".\n",
    "        \"\"\"\n",
    "        self.classes, class_counts = np.unique(y, return_counts=True)\n",
    "        self.class_priors = class_counts / np.sum(class_counts)\n",
    "    \n",
    "    def _set_distribution_parameters_for_classes(self, X, y):\n",
    "        \"\"\"Sets mean and standard deviation for each unique class in vector \"y\" based on it's\n",
    "        samples stored in matrix \"X\".\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: numpy.array\n",
    "            Vector of training samples.\n",
    "        y: numpy.array\n",
    "            Vector containing class id for each training sample in matrix \"X\".\n",
    "        \"\"\"\n",
    "        self.class_feature_mean = np.array(\n",
    "            [np.mean(X[np.argwhere(y == c).flatten()], axis=0) for c in self.classes])\n",
    "        self.class_feature_std = np.array(\n",
    "            [np.std(X[np.argwhere(y == c).flatten()], axis=0) for c in self.classes])\n",
    "        \n",
    "    def _predict_for_sample(self, x):\n",
    "        \"\"\"Classification with usage of Bayes Rule: P(Y|X) = P(X|Y) * P(Y) / P(X)\n",
    "        \n",
    "        where: \n",
    "            \n",
    "            P(Y|X) - Posterior, a probability of sample x belonging to class y given that features \n",
    "                     of sample x are independed and distributed according to distribution of class y\n",
    "                     and it's prior.\n",
    "            P(X|Y) - Probability of sample x given class distribution y.\n",
    "            P(Y)   - Prior, a probability of class y occuring in whole dataset.\n",
    "            P(X)   - Scales the posterior to make it a proper probability distribution. This term \n",
    "                     is ignored as it doesn't affect prediction.\n",
    "                     \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x: numpy.array\n",
    "            Vector of feature values representing sample \"x\".\n",
    "            \n",
    "        Returns:\n",
    "        -----------\n",
    "        predicted_class: object\n",
    "            Returns class for which calculated posterior was the highest.\n",
    "        \"\"\"\n",
    "        class_probabilities = self._gaussian_probabiity_density_function(\n",
    "            x, self.class_feature_mean, self.class_feature_std)\n",
    "        class_posteriors = self.class_priors * np.prod(class_probabilities, axis=1)\n",
    "        predicted_class = self.classes[np.argmax(class_posteriors)]\n",
    "        return predicted_class\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"For each unique class of vector 'y' calculates a representation based on samples in \n",
    "        matrix 'X'. Representation is a mean and standard deviation of each feature describing \n",
    "        samples in matrix 'X'. Stores representations in variables.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: numpy.array\n",
    "            Matrix of samples.\n",
    "        y: numpy.array\n",
    "            Vector of classes for each corresponding sample in matrix 'X'.\n",
    "        \"\"\"\n",
    "        self._set_prior_for_classes(y)\n",
    "        self._set_distribution_parameters_for_classes(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Applies '_predict_for_sample' function for each row in matrix 'X' and returns a \n",
    "        numpy.array of predictions.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: numpy.array\n",
    "            Matrix of samples.\n",
    "        \"\"\"\n",
    "        return np.apply_along_axis(self._predict_for_sample, 1, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T01:58:30.284799Z",
     "start_time": "2020-02-23T01:58:30.272818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train matrix size: (120, 4)\n",
      "y_train vector size: (120,)\n",
      "X_test matrix size: (30, 4)\n",
      "y_test vector size: (30,)\n",
      "\n",
      "----\n",
      "\n",
      "Prediction vector: [0 2 1 1 0 1 0 0 2 1 2 2 2 1 0 0 0 1 1 2 0 2 1 2 2 2 1 0 2 0]\n",
      "  Expected values: [0 2 1 1 0 1 0 0 2 1 2 2 2 1 0 0 0 1 1 2 0 2 1 2 2 1 1 0 2 0]\n",
      "\n",
      "----\n",
      "\n",
      "Prediction accuracy: 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "print(\"X_train matrix size: {}\".format(X_train.shape))\n",
    "print(\"y_train vector size: {}\".format(y_train.shape))\n",
    "print(\"X_test matrix size: {}\".format(X_test.shape))\n",
    "print(\"y_test vector size: {}\".format(y_test.shape))\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Creating Gausian Naive Bayes model\n",
    "nb = GaussianNaiveBayes()\n",
    "\n",
    "# Training model\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Making prediction\n",
    "pred = nb.predict(X_test)\n",
    "print(\"Prediction vector: {}\".format(pred))\n",
    "print(\"  Expected values: {}\".format(y_test))\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(pred, y_test)\n",
    "print(\"Prediction accuracy: {}%\".format(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to scikit-learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T01:58:30.298290Z",
     "start_time": "2020-02-23T01:58:30.286386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train matrix size: (120, 4)\n",
      "y_train vector size: (120,)\n",
      "X_test matrix size: (30, 4)\n",
      "y_test vector size: (30,)\n",
      "\n",
      "----\n",
      "\n",
      "Prediction vector: [0 2 1 1 0 1 0 0 2 1 2 2 2 1 0 0 0 1 1 2 0 2 1 2 2 2 1 0 2 0]\n",
      "  Expected values: [0 2 1 1 0 1 0 0 2 1 2 2 2 1 0 0 0 1 1 2 0 2 1 2 2 1 1 0 2 0]\n",
      "\n",
      "----\n",
      "\n",
      "Prediction accuracy: 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "print(\"X_train matrix size: {}\".format(X_train.shape))\n",
    "print(\"y_train vector size: {}\".format(y_train.shape))\n",
    "print(\"X_test matrix size: {}\".format(X_test.shape))\n",
    "print(\"y_test vector size: {}\".format(y_test.shape))\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Creating Gausian Naive Bayes model\n",
    "scikit_nb = GaussianNB()\n",
    "\n",
    "# Training model\n",
    "scikit_nb.fit(X_train, y_train)\n",
    "\n",
    "# Making prediction\n",
    "pred = scikit_nb.predict(X_test)\n",
    "print(\"Prediction vector: {}\".format(pred))\n",
    "print(\"  Expected values: {}\".format(y_test))\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(pred, y_test)\n",
    "print(\"Prediction accuracy: {}%\".format(accuracy * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
