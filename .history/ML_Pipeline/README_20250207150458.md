# **Machine Learning Pipeline**

This project implements a **modular machine learning pipeline** that allows you to experiment with different datasets and models. The pipeline handles the following tasks:
- **Data loading and splitting**
- **Preprocessing (e.g., handling missing values, feature scaling)**
- **Model training and prediction**
- **Model evaluation**
- **Logging and experimentation with different datasets**

The pipeline is modular, making it easy to experiment with different datasets, preprocessing techniques, and machine learning models.

---

## **Project Structure**
```
your_project/
│── data/                     # Folder containing datasets
│── experiments/              # Folder for running experiments
│── scripts/                  # Folder containing ML pipeline code
│── README.md                 # This README file
```

## **Usage**
1. **Dataset Loading**: The pipeline loads datasets from the `data/` folder. Ensure that the dataset you want to test is placed in the `data/` folder.
   
2. **Configuration**: The `config.py` file contains global settings, such as:
   - `RANDOM_STATE`: For reproducibility.
   - `TEST_SIZE`: The proportion of data used for testing.
   - `MISSING_VALUE_STRATEGY`: Defines how missing values are handled (e.g., using mean or median).
   
3. **Running the Pipeline**: To run the pipeline with a specific experiment (e.g., testing different datasets), execute the corresponding script:
   ```bash
   python experiments/test_different_datasets.py
   ```

   This will process the datasets listed in the `focus.md` file and log the results.

---

## **Running Experiments**
You can experiment with different datasets by modifying the `experiments/test_different_datasets.py` file. This script:
- Loads datasets from the `data/` folder.
- Preprocesses the data (handles missing values and scales features).
- Trains models like Logistic Regression and Random Forest.
- Evaluates the models and logs the accuracy for each dataset.

To add more experiments:
- Add new datasets to the `datasets` list in `test_different_datasets.py`.
- Modify the preprocessing, model training, or evaluation steps to test different configurations.

