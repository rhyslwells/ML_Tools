# how many rows within a dataframe is best for use in a random forest

# Unexpectedly Perfect Model Performance

Perfect accuracy or $F_1$ scores in a model (e.g., Random Forest with few trees) are rarely genuine and often indicate a problem. Such results should be critically investigated.

### Common Causes

* **Data leakage:** Information from the target or test data is present in the training data (e.g., derived features or preprocessing done before splitting).
* **Small or easy dataset:** Highly separable classes, clean features, or limited noise (as in the Iris dataset) can lead to unrealistically high accuracy.
* **Small test set:** A small holdout may not represent the overall data, producing artificially high performance.
* **Sampling bias:** Certain random splits may create an unrepresentative test set.
* **Overfitting:** The model memorizes patterns instead of generalizing.

### Diagnostic Checks

1. **Inspect features** for target dependency or post-target transformations.
2. **Use cross-validation:**

   ```python
   from sklearn.model_selection import cross_val_score
   scores = cross_val_score(model, X, y, cv=5)
   print(scores.mean())
   ```

   Significant drop compared to the test score suggests overfitting or leakage.
3. **Test across random states:**

   ```python
   for seed in [0, 1, 10, 42, 100]:
       X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed)
       model.fit(X_train, y_train)
       print(model.score(X_test, y_test))
   ```

   Large variation implies unstable sampling.
4. **Shuffle target labels:**

   ```python
   from sklearn.utils import shuffle
   y_shuffled = shuffle(y, random_state=42)
   model.fit(X, y_shuffled)
   print(model.score(X, y))
   ```

   High accuracy even with shuffled labels confirms leakage.

### Summary

Perfect model performance should always be treated as a red flag.
Validate using cross-validation, recheck feature preparation, and ensure preprocessing occurs *after* splitting the dataset.

---

#ml #evaluation #ml_process #statistics
