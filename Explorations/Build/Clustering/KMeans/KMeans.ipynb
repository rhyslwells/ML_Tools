{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "def preprocess(df):\n",
    "    #remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    #remove null values\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def scale_features(df,type=\"minmax\"):\n",
    "    if type == \"minmax\":\n",
    "        scaler = MinMaxScaler() # or StandardScaler\n",
    "\n",
    "        df = scaler.fit_transform(df)\n",
    "        return df\n",
    "    if type == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        df = scaler.fit_transform(df)\n",
    "        return df\n",
    "\n",
    "def plot_data(df, x_col, y_col,c_var,title=\"Data Distribution\"):\n",
    "    plt.scatter(df[x_col], df[y_col],c=df[c_var],cmap='viridis')\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_elbow_method(df, features, k_range=(1, 10)):\n",
    "    sse = []\n",
    "    for k in range(*k_range):\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        km.fit(df[features])\n",
    "        sse.append(km.inertia_)\n",
    "    plt.plot(range(*k_range), sse, marker='o')\n",
    "    plt.xlabel('Number of Clusters (K)')\n",
    "    plt.ylabel('Sum of Squared Errors (SSE)')\n",
    "    plt.title('Elbow Method for Optimal K')\n",
    "    plt.show()\n",
    "\n",
    "def perform_kmeans(df, features, n_clusters=3):\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    df['cluster'] = km.fit_predict(df[features])\n",
    "    return km, df\n",
    "\n",
    "def plot_clusters(df, features, km):\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, km.n_clusters))\n",
    "    for i in range(km.n_clusters):\n",
    "        cluster_data = df[df['cluster'] == i]\n",
    "        plt.scatter(cluster_data[features[0]], cluster_data[features[1]], color=colors[i], label=f'Cluster {i}')\n",
    "    plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], color='purple', marker='*', label='Centroids')\n",
    "    plt.xlabel(features[0])\n",
    "    plt.ylabel(features[1])\n",
    "    plt.legend()\n",
    "    plt.title(\"Clustered Data\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = pd.DataFrame(iris.target, columns=['Targets'])\n",
    "iris_df = pd.DataFrame(X, columns=['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.head()\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K-Means clustering\n",
    "clustering = KMeans(n_clusters=3, random_state=5).fit(iris_df)\n",
    "\n",
    "# Relabel clusters to match the ground truth order\n",
    "relabel = np.choose(clustering.labels_, [0, 1, 2]).astype(np.int64)\n",
    "\n",
    "# Define color mapping for correct classifications\n",
    "color_theme = np.array(['red', 'green', 'blue'])\n",
    "\n",
    "# Identify misclassified points\n",
    "misclassified = relabel != y['Targets']\n",
    "colors_with_misclassification = np.where(misclassified, 'black', color_theme[relabel])\n",
    "\n",
    "# Create the plots\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Ground Truth Plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(iris_df.Petal_Length, iris_df.Petal_Width, c=color_theme[y['Targets']], s=50)\n",
    "plt.title('Ground Truth Classification')\n",
    "\n",
    "# K-Means Clustering Plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(iris_df.Petal_Length, iris_df.Petal_Width, c=color_theme[relabel], s=50)\n",
    "plt.title('K-Means Classification')\n",
    "\n",
    "# Misclassified Points Highlighted\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(iris_df.Petal_Length, iris_df.Petal_Width, c=colors_with_misclassification, s=50)\n",
    "plt.title('Misclassified Points Highlighted (Black)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, relabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "df_raw = load_data('data/Categorical.csv')\n",
    "\n",
    "#EDA:\n",
    "df_raw.head()\n",
    "\n",
    "# Plot\n",
    "x='bill_length_mm'\n",
    "y='bill_depth_mm'\n",
    "color='flipper_length_mm' # possibly change plot data to handle categorical\n",
    "x,y,color = 'Longitude', 'Latitude', 'OTHER'\n",
    "plot_data(df_raw, x, y,color)\n",
    "\n",
    "# Pick columns to focus on\n",
    "#Prepare data\n",
    "df_raw['continent_code'] = df_raw['continent'].astype('category').cat.codes\n",
    "x,y,color = 'Longitude', 'Latitude', 'continent_code'\n",
    "# possibly change plot data to handle categorical\n",
    "# pick numerical features\n",
    "features = [x,y,color] # or all numericals\n",
    "# remove na and convert to numericals. \n",
    "preprocess(df_raw)\n",
    "\n",
    "\n",
    "df_minmax=scale_features(df_raw, type='minmax')\n",
    "df_standard=scale_features(df_raw, type='standard')\n",
    "plot_data(df_raw, x, y,color)\n",
    "plot_data(df_raw, x, y,color)\n",
    "\n",
    "df=df_minmax\n",
    "plot_elbow_method(df, features)\n",
    "\n",
    "km=perform_kmeans(df, features, n_clusters=3)[0]\n",
    "plot_clusters(df, features, km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penguins Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = load_data(\"../../../../Datasets/penguins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA:\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "x='bill_length_mm'\n",
    "y='bill_depth_mm'\n",
    "color='flipper_length_mm' # possibly change plot data to handle categorical\n",
    "plot_data(df, x, y,color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick columns to focus on\n",
    "#Prepare data\n",
    "x='bill_length_mm'\n",
    "y='bill_depth_mm'\n",
    "color='flipper_length_mm' # possibly change plot data to handle categorical\n",
    "# pick numerical features\n",
    "features = ['bill_length_mm', 'bill_depth_mm']\n",
    "# remove na and convert to numericals. \n",
    "preprocess(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=scale_features(df_raw, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elbow_method(df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km=perform_kmeans(df, features, n_clusters=3)[0]\n",
    "plot_clusters(df, features, km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(\"data/income.csv\")\n",
    "\n",
    "# Pipeline\n",
    "df_raw = load_data(\"../../../../Datasets/penguins.csv\")\n",
    "\n",
    "#EDA:\n",
    "df_raw.head()\n",
    "\n",
    "# Plot\n",
    "x='bill_length_mm'\n",
    "y='bill_depth_mm'\n",
    "color='flipper_length_mm' # possibly change plot data to handle categorical\n",
    "plot_data(df, x, y,color)\n",
    "\n",
    "# Pick columns to focus on\n",
    "#Prepare data\n",
    "x='bill_length_mm'\n",
    "y='bill_depth_mm'\n",
    "color='flipper_length_mm' # possibly change plot data to handle categorical\n",
    "# pick numerical features\n",
    "features = ['bill_length_mm', 'bill_depth_mm']\n",
    "# remove na and convert to numericals. \n",
    "preprocess(df_raw)\n",
    "\n",
    "df=scale_features(df_raw, features)\n",
    "\n",
    "plot_elbow_method(df, features)\n",
    "\n",
    "km=perform_kmeans(df, features, n_clusters=3)[0]\n",
    "plot_clusters(df, features, km)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
