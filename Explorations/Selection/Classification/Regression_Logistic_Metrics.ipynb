{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at Logistic Regression Metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "FILEPATH = '../../../../Datasets/Binary_predictors.csv'\n",
    "data = pd.read_csv(FILEPATH)\n",
    "\n",
    "# Encode categorical variables\n",
    "data['Admitted'] = data['Admitted'].map({'Yes': 1, 'No': 0})\n",
    "data['Gender'] = data['Gender'].map({'Female': 1, 'Male': 0})\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "train_data = data.sample(frac=0.8, random_state=2000)\n",
    "test_data = data.drop(train_data.index)\n",
    "# Define target variable and predictors\n",
    "\n",
    "# The constant is added using sm.add_constant() to include an intercept term in the logistic regression model. statsmodels does not do this automatically.\n",
    "X_train = sm.add_constant(train_data[['SAT', 'Gender']])\n",
    "X_test = sm.add_constant(test_data[['SAT', 'Gender']])\n",
    "\n",
    "y_train = train_data['Admitted']\n",
    "y_test = test_data['Admitted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.093311\n",
      "         Iterations 11\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Admitted   No. Observations:                  134\n",
      "Model:                          Logit   Df Residuals:                      131\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 17 Mar 2025   Pseudo R-squ.:                  0.8636\n",
      "Time:                        15:02:16   Log-Likelihood:                -12.504\n",
      "converged:                       True   LL-Null:                       -91.669\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.158e-35\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -91.2887     29.907     -3.052      0.002    -149.905     -32.672\n",
      "SAT            0.0543      0.018      3.042      0.002       0.019       0.089\n",
      "Gender         2.1717      1.126      1.928      0.054      -0.036       4.379\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.46 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression model\n",
    "model = sm.Logit(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display regression summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stats model Metrics\n",
    "# Exponentiate coefficients for interpretation\n",
    "exp_coef = np.exp(results.params)\n",
    "print(\"Exponentiated Coefficients:\", exp_coef)\n",
    "# Compute training accuracy\n",
    "def compute_accuracy(actual, predicted):\n",
    "    \"\"\"\n",
    "    Compute accuracy given actual labels and predicted probabilities.\n",
    "    \"\"\"\n",
    "    bins = np.array([0, 0.5, 1])\n",
    "    cm = np.histogram2d(actual, predicted, bins=bins)[0]\n",
    "    accuracy = (cm[0, 0] + cm[1, 1]) / cm.sum()\n",
    "    return cm, accuracy\n",
    "\n",
    "train_predictions = results.predict()\n",
    "cm_train, accuracy_train = compute_accuracy(y_train, train_predictions)\n",
    "print(f'Training Accuracy: {accuracy_train:.2f}')\n",
    "# Compute confusion matrix and accuracy for test data\n",
    "test_predictions = results.predict(X_test)\n",
    "cm_test, accuracy_test = compute_accuracy(y_test, test_predictions)\n",
    "\n",
    "# Format and display confusion matrix\n",
    "cm_df = pd.DataFrame(cm_test, columns=['Predicted 0', 'Predicted 1'], index=['Actual 0', 'Actual 1'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)\n",
    "# Display test accuracy and misclassification rate\n",
    "print(f'Test Accuracy: {accuracy_test:.2f}')\n",
    "print(f'Misclassification Rate: {1 - accuracy_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated Coefficients: const     2.258522e-40\n",
      "SAT       1.055779e+00\n",
      "Gender    8.773478e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Exponentiate coefficients for interpretation\n",
    "exp_coef = np.exp(results.params)\n",
    "print(\"Exponentiated Coefficients:\", exp_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Compute training accuracy\n",
    "def compute_accuracy(actual, predicted):\n",
    "    \"\"\"\n",
    "    Compute accuracy given actual labels and predicted probabilities.\n",
    "    \"\"\"\n",
    "    bins = np.array([0, 0.5, 1])\n",
    "    cm = np.histogram2d(actual, predicted, bins=bins)[0]\n",
    "    accuracy = (cm[0, 0] + cm[1, 1]) / cm.sum()\n",
    "    return cm, accuracy\n",
    "\n",
    "train_predictions = results.predict()\n",
    "cm_train, accuracy_train = compute_accuracy(y_train, train_predictions)\n",
    "print(f'Training Accuracy: {accuracy_train:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0         14.0          2.0\n",
      "Actual 1          2.0         16.0\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix and accuracy for test data\n",
    "test_predictions = results.predict(X_test)\n",
    "cm_test, accuracy_test = compute_accuracy(y_test, test_predictions)\n",
    "\n",
    "# Format and display confusion matrix\n",
    "cm_df = pd.DataFrame(cm_test, columns=['Predicted 0', 'Predicted 1'], index=['Actual 0', 'Actual 1'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.88\n",
      "Misclassification Rate: 0.12\n"
     ]
    }
   ],
   "source": [
    "# Display test accuracy and misclassification rate\n",
    "print(f'Test Accuracy: {accuracy_test:.2f}')\n",
    "print(f'Misclassification Rate: {1 - accuracy_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn model metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will the metrics calculated by statsmodel and sklearn be the same/similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Sklearn):\n",
      "[[14  2]\n",
      " [ 2 16]]\n",
      "Accuracy (Sklearn): 0.88\n",
      "Misclassification Rate (Sklearn): 0.12\n"
     ]
    }
   ],
   "source": [
    "# Sklearn model fitting\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train[['const', 'SAT', 'Gender']], y_train)  # Don't pass 'const' as it is manually added.\n",
    "\n",
    "# Predictions\n",
    "y_pred_prob = model.predict_proba(X_test[['const', 'SAT', 'Gender']])[:, 1]  # Probabilities for class 1\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)  # Apply threshold to get predicted labels (0 or 1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix (Sklearn):\")\n",
    "print(cm)\n",
    "\n",
    "# Compute Accuracy manually (same as in your statsmodels code)\n",
    "accuracy = (cm[0, 0] + cm[1, 1]) / cm.sum()\n",
    "print(f'Accuracy (Sklearn): {accuracy:.2f}')\n",
    "\n",
    "# Misclassification rate\n",
    "misclassification_rate = 1 - accuracy\n",
    "print(f'Misclassification Rate (Sklearn): {misclassification_rate:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
